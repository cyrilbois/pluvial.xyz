---
title: Twitter
---

# Twitter

[Simon Willison’s Weblog](https://simonwillison.net/)

[Predictable updating about AI risk - Joe Carlsmith](https://joecarlsmith.com/2023/05/08/predictable-updating-about-ai-risk)

[Strong Evidence is Common](https://markxu.com/strong-evidence)

[On the Universal Distribution - Joe Carlsmith](https://joecarlsmith.com/2021/10/29/on-the-universal-distribution#i-the-universal-distribution)

[Toolbox-thinking and Law-thinking - LessWrong](https://www.lesswrong.com/posts/CPP2uLcaywEokFKQG/toolbox-thinking-and-law-thinking)

[Playing the training game](https://www.planned-obsolescence.org/the-training-game/)

[How might we align transformative AI if it’s developed very soon? - LessWrong](https://www.lesswrong.com/posts/rCJQAkPTEypGjSJ8X/how-might-we-align-transformative-ai-if-it-s-developed-very#Testing_and_threat_assessment)

[(9) Eliezer Yudkowsky on Twitter: "Another way of breaking loose of 'arguments': Any time somebody manages to persuade you of something via much hard work, do not neglect to remember that you would, if you had been smarter, probably have been persuadable by the empty string." / Twitter](https://twitter.com/ESYudkowsky/status/1500863629490544645)

[[1906.01820] Risks from Learned Optimization in Advanced Machine Learning Systems](https://arxiv.org/abs/1906.01820)

[[2210.01790] Goal Misgeneralization: Why Correct Specifications Aren't Enough For Correct Goals](https://arxiv.org/abs/2210.01790)

[AI Safety Seems Hard to Measure - EA Forum](https://forum.effectivealtruism.org/posts/NbiHKTN5QhFFfjjm5/ai-safety-seems-hard-to-measure#_2__The_King_Lear_problem__how_do_you_test_what_will_happen_when_it_s_no_longer_a_test_)

[This GPT-4 answer speaks for itself - Marginal REVOLUTION](https://marginalrevolution.com/marginalrevolution/2023/04/this-gpt-4-answer-speaks-for-itself.html)

[Kokotajlo Review of JC Alignment Report - Google Docs](https://docs.google.com/document/d/1GwT7AS_PWpglWWrVrpiMqeKiJ_E2VgAUIG5tTdVhVeM/edit#heading=h.e9o5m3fab0ua)

[Is Power-Seeking AI an Existential Risk? - 2206.13353.pdf](https://arxiv.org/pdf/2206.13353.pdf)

[AI Could Defeat All Of Us Combined](https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/)

[AI Wins IMO Gold Medal | Metaculus](https://www.metaculus.com/questions/6728/ai-wins-imo-gold-medal/)

[Yes Requires the Possibility of No - LessWrong](https://www.lesswrong.com/posts/G5TwJ9BGxcgh5DsmQ/yes-requires-the-possibility-of-no)

[Exaggerating the risks (Part 6: Introducing the Carlsmith report) - Reflective altruism](https://ineffectivealtruismblog.com/2023/04/08/exaggerating-risks-carlsmith-report/)

[Mistakes with Conservation of Expected Evidence - LessWrong](https://www.lesswrong.com/posts/zTfSXQracE7TW8x4w/mistakes-with-conservation-of-expected-evidence)

[Rational predictions often update predictably* - EA Forum](https://forum.effectivealtruism.org/posts/Lto9awEYPQNu9wkdi/rational-predictions-often-update-predictably)

[Conservation of Expected Evidence - LessWrong](https://www.lesswrong.com/posts/jiBFC7DcCrZjGmZnJ/conservation-of-expected-evidence)

[Rational predictions often update predictably* - EA Forum](https://forum.effectivealtruism.org/posts/Lto9awEYPQNu9wkdi/rational-predictions-often-update-predictably#fn6am2fn0yyve)

[Mantic Monday 3/14/22 - by Scott Alexander](https://astralcodexten.substack.com/p/mantic-monday-31422)

[Believing in things you cannot see - Joe Carlsmith](https://joecarlsmith.com/2021/01/31/believing-in-things-you-cannot-see)

[Thoughts on being mortal - Joe Carlsmith](https://joecarlsmith.com/2020/12/06/thoughts-on-being-mortal#iii)

[Noticing Confusion - Sequence](https://www.readthesequences.com/Noticing-Confusion-Sequence)

[Simulation arguments - simulation_arguments_revised.pdf](https://jc.gatspress.com/pdf/simulation_arguments_revised.pdf)

[List of Cognitive Biases and Heuristics - The Decision Lab](https://thedecisionlab.com/biases)

[The Missing Moods - Econlib](https://www.econlib.org/archives/2016/01/the_invisible_t.html)

[Mental Health and the Alignment Problem: A Compilation of Resources (updated April 2023) - LessWrong](https://www.lesswrong.com/posts/pLLeGA7aGaJpgCkof/mental-health-and-the-alignment-problem-a-compilation-of)

[This Can't Go On](https://www.cold-takes.com/this-cant-go-on/)

[Tom Murphy 7's Invincible Web Page](http://tom7.org/)

[Tom 7 Radar](http://radar.spacebar.org/)

[Dynamic import is not enabled in this context (deno-deploy) · Issue #40 · pluvial/svelte-adapter-deno](https://github.com/pluvial/svelte-adapter-deno/issues/40)

[Building a Signal Analyzer with Modern Web Tech - Casey Primozic's Homepage](https://cprimozic.net/blog/building-a-signal-analyzer-with-modern-web-tech/)

[(10) John A De Goes on Twitter: "Boss: Why should I let you choose programming language&gt;? Go: So the developers you hire when I rage-quit over lack of proper generics and result enums can instantly take over and maintain my code. Haskell: So we can intimidate our intellectually weak competitors who dared…" / Twitter](https://twitter.com/jdegoes/status/1662099523538132997)

[Geoff Rich on Twitter: "Stumbled on some very strange (AI-generated?) tweets about SvelteKit. So weird, there's tons of these if you search for "SvelteKit" and sort by latest. https://t.co/4MCIGer93z" / Twitter](https://twitter.com/geoffrich_/status/1662128929988304896)

[(10) Cameron R. Wolfe on Twitter: "We all know that LLMs tend to make errors, whether it be simple mistakes (e.g., improper arithmetic), hallucinations, or something else. But, studying the statistics of mistakes that LLMs make shows us something that we might not intuitively expect. Background: One way to study… https://t.co/MaqYYqhrWA" / Twitter](https://twitter.com/cwolferesearch/status/1661837922671140897)

[(10) Talia Ringer on Twitter: "New preprint just dropped! "Can Transformers Learn to Solve Problems Recursively?" With @dylanszzhang, @CurtTigges, @BlancheMinerva, @mraginsky, and @TaliaRinger. https://t.co/D13mD2Q7aq https://t.co/wqM2FPQEQ4" / Twitter](https://twitter.com/TaliaRinger/status/1661786081249964050)

[Aran Komatsuzaki on Twitter: "SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning Outperforms all SotA RL baselines, trained for 1M steps, without any training. https://t.co/SJbnVHaAdf https://t.co/9s8p2sBe1d" / Twitter](https://twitter.com/arankomatsuzaki/status/1661909042007031809)

[Kelly Vaughn on Twitter: "My friends. Think before you use Chat GPT during the interview process. https://t.co/7yMp8CGyBu" / Twitter](https://twitter.com/kvlly/status/1661545252027609090)

[(10) gfodor.id on Twitter: "My intuition as a software engineer and shoggoth whisperer is that the flailing AutoGPT situation is misleading. Some schizo is going to find a niche where something meaningful breaks through for some bizarre and inexplicable reason and then the Carmacks of the world flood in." / Twitter](https://twitter.com/gfodor/status/1661746251187261447)

[tiiuae/falcon-40b · Hugging Face](https://huggingface.co/tiiuae/falcon-40b)

[Open LLM Leaderboard - a Hugging Face Space by HuggingFaceH4](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)

[Chatbot Arena Leaderboard Updates (Week 4) | LMSYS Org](https://lmsys.org/blog/2023-05-25-leaderboard/)

[artidoro/qlora: QLoRA: Efficient Finetuning of Quantized LLMs](https://github.com/artidoro/qlora)

[Hugging Face – Blog](https://huggingface.co/blog)

[Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA](https://huggingface.co/blog/4bit-transformers-bitsandbytes)

[Guanaco Playground Tgi - a Hugging Face Space by uwnlp](https://huggingface.co/spaces/uwnlp/guanaco-playground-tgi)

[Stability-AI/StableStudio: Community interface for generative AI](https://github.com/Stability-AI/StableStudio)

[Reimagine XL](https://clipdrop.co/stable-diffusion-reimagine?utm_source=website&utm_medium=blog&utm_campaign=Clipdrop+reimagine+xl)

[Async/await and promises | DeviceScript](https://microsoft.github.io/devicescript/language/async)

[microsoft/devicescript: TypeScript for Tiny IoT Devices](https://github.com/microsoft/devicescript/tree/main)

[Diagram · Design tools from the future.](https://diagram.com/)

[naviserver / naviserver — Bitbucket](https://bitbucket.org/naviserver/naviserver/src/main/)

[aolserver/aolserver: AOLserver is America Online's Open-Source web server. AOLserver is the backbone of the largest and busiest production environments in the world. AOLserver is a multithreaded, Tcl-enabled web server used for large scale, dynamic web sites.](https://github.com/AOLserver/AOLserver)

[(10) AK on Twitter: "Open AI releases paper + dataset Let’s Verify Step by Step trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (“process supervision”) instead of simply rewarding the correct final answer (“outcome… https://t.co/M6PwkqBLL9" / Twitter](https://twitter.com/_akhaliq/status/1663981726647894027)

[(10) Roberto Nickson on Twitter: "Adam Mosseri (Instagram CEO) just explained exactly how the Instagram algorithm works, and how they rank content in stories, feed, reels &amp; explore. The last slides are most important. It's how I've added 500K followers to my accounts in 4 months. Here's what you need to know:" / Twitter](https://twitter.com/rpnickson/status/1663967264192987137)

[Matt Shumer on Twitter: "Is anyone else noticing significantly downgraded GPT-4 capabilities today? Seems like OpenAI updated the model, and results aren’t as good as before." / Twitter](https://twitter.com/mattshumer_/status/1663744527448829954)

[Ask HN: Is it just me or GPT-4's quality has significantly deteriorated lately? | Hacker News](https://news.ycombinator.com/item?id=36134249)

[(10) Ate-a-Pi on Twitter: "This OpenAI paper might as well have been titled “Moving Away From PaperClip Maxxing” So good - they took a base GPT-4, fine tuned it a bit on math so that it understood the language as well as the output format - then no RL. Instead they trained and compared two reward… https://t.co/3Tdi2kep98" / Twitter](https://twitter.com/8teAPi/status/1664123104074022917)

[(10) Carter Anderson on Twitter: "I use Rust because there is literally nothing else on the market like it. The character of other "similar" languages (Zig, Go, C++, Jai, etc) is completely different. The developer community is the best I have ever been in, despite the hiccups here and there." / Twitter](https://twitter.com/cart_cart/status/1664064410086780931)

[(10) bowser on Twitter: "i wonder how many people know that camera sensor noise is unique so if you post pictures from the same camera on main and alt they can be linked" / Twitter](https://twitter.com/browserdotsys/status/1664070479760482304)

[Tau: Accurate AI Software Generation with Guaranteed AI Safety](https://tau.net/)
