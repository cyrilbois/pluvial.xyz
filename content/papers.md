---
title: Papers
---

# Papers

[[2002.05645] Training Large Neural Networks with Constant Memory using a New Execution Algorithm](https://ar5iv.labs.arxiv.org/html/2002.05645?fallback=original#microsoft)

[[1812.04948] A Style-Based Generator Architecture for Generative Adversarial Networks](https://ar5iv.labs.arxiv.org/html/1812.04948?fallback=original#nvidia)

[[2107.06917] A Field Guide to Federated Optimization](https://ar5iv.labs.arxiv.org/html/2107.06917?fallback=original#google)

[[1511.05641] Net2Net: Accelerating Learning via Knowledge Transfer](https://ar5iv.labs.arxiv.org/html/1511.05641?fallback=original)

[[2104.03113] Scaling Scaling Laws with Board Games](https://ar5iv.labs.arxiv.org/html/2104.03113?fallback=original)

[[2105.12806] A Universal Law of Robustness via Isoperimetry](https://ar5iv.labs.arxiv.org/html/2105.12806?fallback=original)

[[2006.10621] On the Predictability of Pruning Across Scales](https://ar5iv.labs.arxiv.org/html/2006.10621?fallback=original)

[[2106.05237] Knowledge distillation: A good teacher is patient and consistent](https://ar5iv.labs.arxiv.org/html/2106.05237?fallback=original#google)

[[2009.06807] The Radicalization Risks of GPT-3 and Advanced Neural Language Models](https://ar5iv.labs.arxiv.org/html/2009.06807?fallback=original)

[[1712.02950] CycleGAN, a Master of Steganography](https://ar5iv.labs.arxiv.org/html/1712.02950?fallback=original)

[[2010.03660] Fast Stencil-Code Computation on a Wafer-Scale Processor](https://ar5iv.labs.arxiv.org/html/2010.03660?fallback=original#cerebras)

[[2205.05131] UL2: Unifying Language Learning Paradigms](https://ar5iv.labs.arxiv.org/html/2205.05131?fallback=original#google)

[[2203.15556] Training Compute-Optimal Large Language Models](https://ar5iv.labs.arxiv.org/html/2203.15556?fallback=original#deepmind)

[[2203.03466] Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer](https://ar5iv.labs.arxiv.org/html/2203.03466?fallback=original)

[[2108.07686] Untitled Document](https://ar5iv.labs.arxiv.org/html/2108.07686?fallback=original)

[[2110.05457] Legged Robots that Keep on Learning: Fine-Tuning Locomotion Policies in the Real World](https://ar5iv.labs.arxiv.org/html/2110.05457?fallback=original)

[[1910.07113] Solving Rubik‚Äôs Cube with a Robot Hand](https://ar5iv.labs.arxiv.org/html/1910.07113?fallback=original#openai)

[[1901.08652] Learning Agile and Dynamic Motor Skills for Legged Robots](https://ar5iv.labs.arxiv.org/html/1901.08652?fallback=original)

[[2202.06009] Maximizing Communication Efficiency for Large-scale Training via 0/1 Adam](https://ar5iv.labs.arxiv.org/html/2202.06009?fallback=original#microsoft)

[[1608.05343] Decoupled Neural Interfaces using Synthetic Gradients](https://ar5iv.labs.arxiv.org/html/1608.05343?fallback=original#deepmind)

[[1809.02942] Cellular automata as convolutional neural networks](https://ar5iv.labs.arxiv.org/html/1809.02942?fallback=original)

[[2102.02579] Regenerating Soft Robots through Neural Cellular Automata](https://ar5iv.labs.arxiv.org/html/2102.02579?fallback=original)

[[2103.08737] Growing 3D Artefacts and Functional Machines with Neural Cellular Automata](https://ar5iv.labs.arxiv.org/html/2103.08737?fallback=original)

[[2105.07299] Texture Generation with Neural Cellular Automata](https://ar5iv.labs.arxiv.org/html/2105.07299?fallback=original)

[[2201.12360] Variational Neural Cellular Automata](https://ar5iv.labs.arxiv.org/html/2201.12360?fallback=original)

[[2111.13545] ùúáNCA: Texture Generation with Ultra-Compact Neural Cellular Automata](https://ar5iv.labs.arxiv.org/html/2111.13545?fallback=original)

[[1904.11455] Ray Interference: a Source of Plateaus in Deep Reinforcement Learning](https://ar5iv.labs.arxiv.org/html/1904.11455?fallback=original#deepmind)

[[1609.09106] Untitled Document](https://ar5iv.labs.arxiv.org/html/1609.09106?fallback=original#google)

[[1511.09249] On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models Technical Report](https://ar5iv.labs.arxiv.org/html/1511.09249?fallback=original#schmidhuber)

[[1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model](https://ar5iv.labs.arxiv.org/html/1911.08265?fallback=original#deepmind)

[[2103.10948] The Shape of Learning Curves: a Review](https://ar5iv.labs.arxiv.org/html/2103.10948?fallback=original)

[[2106.10207] Distributed Deep Learning In Open Collaborations](https://ar5iv.labs.arxiv.org/html/2106.10207?fallback=original)

[[2004.08366] DynamicEmbedding: Extending TensorFlow for Colossal-Scale Applications](https://ar5iv.labs.arxiv.org/html/2004.08366?fallback=original#google)

[[1812.06162] An Empirical Model of Large-Batch Training](https://ar5iv.labs.arxiv.org/html/1812.06162?fallback=original#openai)

[[1802.08864] One Big Net For Everything Technical Report](https://ar5iv.labs.arxiv.org/html/1802.08864?fallback=original#schmidhuber)

[[2102.01293] Scaling Laws for Transfer](https://ar5iv.labs.arxiv.org/html/2102.01293?fallback=original#openai)

[[1906.01820] Risks from Learned Optimization in Advanced Machine Learning Systems](https://ar5iv.labs.arxiv.org/html/1906.01820?fallback=original)

[[2205.06175] A Generalist Agent](https://ar5iv.labs.arxiv.org/html/2205.06175?fallback=original#deepmind)

[[2005.14165] Language Models are Few-Shot Learners](https://ar5iv.labs.arxiv.org/html/2005.14165?fallback=original#openai)

[[2106.08254] BEiT: BERT Pre-Training of Image Transformers](https://ar5iv.labs.arxiv.org/html/2106.08254?fallback=original#microsoft)

[[2112.09332] WebGPT: Browser-assisted question-answering with human feedback](https://ar5iv.labs.arxiv.org/html/2112.09332?fallback=original#openai)

[[2202.08137] A data-driven approach for learning to control computers](https://ar5iv.labs.arxiv.org/html/2202.08137?fallback=original#deepmind)

[[2112.03178] Player of Games](https://ar5iv.labs.arxiv.org/html/2112.03178?fallback=original#deepmind)

[[2107.12808] Open-Ended Learning Leads to Generally Capable Agents](https://ar5iv.labs.arxiv.org/html/2107.12808?fallback=original#deepmind)

[[2105.12196] From Motor Control to Team Play in Simulated Humanoid Football](https://ar5iv.labs.arxiv.org/html/2105.12196?fallback=original#deepmind)

[[2009.01719] Grounded Language Learning Fast and Slow](https://ar5iv.labs.arxiv.org/html/2009.01719?fallback=original#deepmind)

[[2012.05672] Imitating Interactive Intelligence](https://ar5iv.labs.arxiv.org/html/2012.05672?fallback=original#deepmind)

[[2110.15349] Learning to Ground Multi-Agent Communication with Autoencoders](https://ar5iv.labs.arxiv.org/html/2110.15349?fallback=original)

[[2110.08176] Collaborating with Humans without Human Data](https://ar5iv.labs.arxiv.org/html/2110.08176?fallback=original#deepmind)

[[2201.01816] Hidden Agenda: a Social Deduction Game with Diverse Learned Equilibria](https://ar5iv.labs.arxiv.org/html/2201.01816?fallback=original)

[[2103.04000] Off-Belief Learning](https://ar5iv.labs.arxiv.org/html/2103.04000?fallback=original#facebook)

[[2104.07219] Multitasking Inhibits Semantic Drift](https://ar5iv.labs.arxiv.org/html/2104.07219?fallback=original)

[[2004.02967] Evolving Normalization-Activation Layers](https://ar5iv.labs.arxiv.org/html/2004.02967?fallback=original#deepmind)

[[2007.03898] NVAE: A Deep Hierarchical Variational Autoencoder](https://ar5iv.labs.arxiv.org/html/2007.03898?fallback=original#nvidia)

[[2011.10650] Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images](https://ar5iv.labs.arxiv.org/html/2011.10650?fallback=original#openai)

[[1512.03385] Deep Residual Learning for Image Recognition](https://ar5iv.labs.arxiv.org/html/1512.03385?fallback=original#microsoft)

[[2108.05818] PatrickStar: Parallel Training of Pre-trained Models via Chunk-based Dynamic Memory Management](https://ar5iv.labs.arxiv.org/html/2108.05818?fallback=original#tencent)

[[2203.12533] 1 Introduction](https://ar5iv.labs.arxiv.org/html/2203.12533?fallback=original#google)

[[2105.04663] GSPMD: General and Scalable Parallelization for ML Computation Graphs](https://ar5iv.labs.arxiv.org/html/2105.04663?fallback=original#google)

[[2107.06925] Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines](https://ar5iv.labs.arxiv.org/html/2107.06925?fallback=original)

[[2104.04473] Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://ar5iv.labs.arxiv.org/html/2104.04473?fallback=original#nvidia)

[[2102.07988] TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models](https://ar5iv.labs.arxiv.org/html/2102.07988?fallback=original)

[[2104.04657] Meta-Learning Bidirectional Update Rules](https://ar5iv.labs.arxiv.org/html/2104.04657?fallback=original#google)

[[2012.14905] Meta Learning Backpropagation And Improving It](https://ar5iv.labs.arxiv.org/html/2012.14905?fallback=original#schmidhuber)

[[2003.03384] AutoML-Zero: Evolving Machine Learning Algorithms From Scratch](https://ar5iv.labs.arxiv.org/html/2003.03384?fallback=original#google)

[[1706.03762] Attention Is All You Need](https://ar5iv.labs.arxiv.org/html/1706.03762?fallback=original#google)

[[1610.06258] Using Fast Weights to Attend to the Recent Past](https://ar5iv.labs.arxiv.org/html/1610.06258?fallback=original#deepmind)

[[1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model](https://ar5iv.labs.arxiv.org/html/1911.08265?fallback=original#deepmind)
